{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install folktables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSIncome, ACSEmployment, ACSTravelTime, ACSDataSource\n",
    "import numpy as np\n",
    "import folktables\n",
    "import pandas as pd\n",
    "# from DPL.RegularizationLoss import RegularizationLoss\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year=\"2014\", horizon=\"5-Year\", survey=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_employment_dataset():\n",
    "    ACSEmployment = folktables.BasicProblem(\n",
    "        features=[\n",
    "            \"AGEP\",\n",
    "            \"SCHL\",\n",
    "            \"MAR\",\n",
    "            \"RELP\",\n",
    "            \"DIS\",\n",
    "            \"ESP\",\n",
    "            \"CIT\",\n",
    "            \"MIG\",\n",
    "            \"MIL\",\n",
    "            \"ANC\",\n",
    "            \"NATIVITY\",\n",
    "            \"DEAR\",\n",
    "            \"DEYE\",\n",
    "            \"DREM\",\n",
    "            \"SEX\",\n",
    "            \"RAC1P\",\n",
    "        ],\n",
    "        target=\"ESR\",\n",
    "        target_transform=lambda x: x == 1,\n",
    "        group=\"SEX\",\n",
    "        preprocess=lambda x: x,\n",
    "        postprocess=lambda x: np.nan_to_num(x, -1),\n",
    "    )\n",
    "    # states = None\n",
    "    # for year in [2014, 2015, 2016, 2017, 2018, 2019]:\n",
    "    year = 2014\n",
    "    states = [\"AL\"]\n",
    "    data_source = ACSDataSource(survey_year=year, horizon=\"1-Year\", survey=\"person\")\n",
    "    acs_data = data_source.get_data(states=states, download=True)\n",
    "    features, label, group = ACSEmployment.df_to_numpy(acs_data)\n",
    "    feature_pd, label_pd, group_pd = ACSEmployment.df_to_pandas(acs_data)\n",
    "    return features, label, group, feature_pd, label_pd, group_pd\n",
    "\n",
    "\n",
    "def adult_filter(data):\n",
    "    \"\"\"Mimic the filters in place for Adult data.\n",
    "\n",
    "    Adult documentation notes: Extraction was done by Barry Becker from\n",
    "    the 1994 Census database. A set of reasonably clean records was extracted\n",
    "    using the following conditions:\n",
    "    ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    \"\"\"\n",
    "    df = data\n",
    "    df = df[df[\"AGEP\"] > 16]\n",
    "    df = df[df[\"PINCP\"] > 100]\n",
    "    df = df[df[\"WKHP\"] > 0]\n",
    "    df = df[df[\"PWGTP\"] >= 1]\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_income_dataset():\n",
    "    ACSIncome = folktables.BasicProblem(\n",
    "        features=[\n",
    "            \"AGEP\",\n",
    "            \"COW\",\n",
    "            \"SCHL\",\n",
    "            \"MAR\",\n",
    "            \"OCCP\",\n",
    "            \"POBP\",\n",
    "            \"RELP\",\n",
    "            \"WKHP\",\n",
    "            \"SEX\",\n",
    "            \"RAC1P\",\n",
    "        ],\n",
    "        target=\"PINCP\",\n",
    "        target_transform=lambda x: x > 50000,\n",
    "        group=\"SEX\",\n",
    "        preprocess=adult_filter,\n",
    "        postprocess=lambda x: np.nan_to_num(x, -1),\n",
    "    )\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    state_list = [\n",
    "        \"AL\",\n",
    "        \"AK\",\n",
    "        \"AZ\",\n",
    "        \"AR\",\n",
    "        \"CA\",\n",
    "        \"CO\",\n",
    "        \"CT\",\n",
    "        \"DE\",\n",
    "        \"FL\",\n",
    "        \"GA\",\n",
    "        \"HI\",\n",
    "        \"ID\",\n",
    "        \"IL\",\n",
    "        \"IN\",\n",
    "        \"IA\",\n",
    "        \"KS\",\n",
    "        \"KY\",\n",
    "        \"LA\",\n",
    "        \"ME\",\n",
    "        \"MD\",\n",
    "        \"MA\",\n",
    "        \"MI\",\n",
    "        \"MN\",\n",
    "        \"MS\",\n",
    "        \"MO\",\n",
    "        \"MT\",\n",
    "        \"NE\",\n",
    "        \"NV\",\n",
    "        \"NH\",\n",
    "        \"NJ\",\n",
    "        \"NM\",\n",
    "        \"NY\",\n",
    "        \"NC\",\n",
    "        \"ND\",\n",
    "        \"OH\",\n",
    "        \"OK\",\n",
    "        \"OR\",\n",
    "        \"PA\",\n",
    "        \"RI\",\n",
    "        \"SC\",\n",
    "        \"SD\",\n",
    "        \"TN\",\n",
    "        \"TX\",\n",
    "        \"UT\",\n",
    "        \"VT\",\n",
    "        \"VA\",\n",
    "        \"WA\",\n",
    "        \"WV\",\n",
    "        \"WI\",\n",
    "        \"WY\",\n",
    "        \"PR\",\n",
    "    ]\n",
    "    for year in [2014, 2015, 2016, 2017, 2018, 2019]:\n",
    "        for state in state_list:\n",
    "            data_source = ACSDataSource(\n",
    "                survey_year=year, horizon=\"1-Year\", survey=\"person\"\n",
    "            )\n",
    "            acs_data = data_source.get_data(states=[state], download=True)\n",
    "            try:\n",
    "                features, label, group = ACSIncome.df_to_numpy(acs_data)\n",
    "                print(features)\n",
    "                feature_pd, label_pd, group_pd = ACSIncome.df_to_pandas(acs_data)\n",
    "                print(feature_pd)\n",
    "                if state not in data:\n",
    "                    data[state] = {}\n",
    "                    data[state][\"features\"] = features\n",
    "                    data[state][\"labels\"] = label\n",
    "                    data[state][\"groups\"] = group\n",
    "                    data[state][\"features_pd\"] = feature_pd\n",
    "                    data[state][\"labels_pd\"] = label_pd\n",
    "                    data[state][\"groups_pd\"] = group_pd\n",
    "                else:\n",
    "                    data[state][\"features\"] = np.concatenate(\n",
    "                        (data[state][\"features\"], features), axis=0\n",
    "                    )\n",
    "                    data[state][\"labels\"] = np.concatenate(\n",
    "                        (data[state][\"labels\"], label), axis=0\n",
    "                    )\n",
    "                    data[state][\"groups\"] = np.concatenate(\n",
    "                        (data[state][\"groups\"], group), axis=0\n",
    "                    )\n",
    "                    data[state][\"features_pd\"] = pd.concat(\n",
    "                        (data[state][\"features_pd\"], feature_pd), axis=0\n",
    "                    )\n",
    "                    data[state][\"labels_pd\"] = pd.concat(\n",
    "                        (data[state][\"labels_pd\"], label_pd), axis=0\n",
    "                    )\n",
    "                    data[state][\"groups_pd\"] = pd.concat(\n",
    "                        (data[state][\"groups_pd\"], group_pd), axis=0\n",
    "                    )\n",
    "            except:\n",
    "                print(\"Error with state: \", state, \" and year: \", year)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = create_income_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_disparity(disparities):\n",
    "    # plot the disparities of the different states\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.bar(range(len(disparities)), list(disparities.values()), align=\"center\")\n",
    "    plt.xticks(range(len(disparities)), list(disparities.keys()))\n",
    "    plt.xlabel(\"State\")\n",
    "    plt.ylabel(\"Disparity\")\n",
    "    plt.title(\"Income Disparity\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_bar_plot(data):\n",
    "    # plot a bar plot of the different <label, group> pairs for each state\n",
    "    clients_target_sensitive = []\n",
    "    for state in data.keys():\n",
    "        labels = data[state][\"labels\"].astype(int)\n",
    "        group = [1 if item == 1 else 0 for item in list(data[state][\"groups\"])]\n",
    "\n",
    "        labels_and_group = list(zip(labels, group))\n",
    "        clients_target_sensitive.append(labels_and_group)\n",
    "\n",
    "    counter_groups = [Counter(client_data) for client_data in clients_target_sensitive]\n",
    "    print(counter_groups[0])\n",
    "    print(counter_groups[-1])\n",
    "    counter_group_0_0 = [counter[(0, 0.0)] for counter in counter_groups]\n",
    "    counter_group_0_1 = [counter[(0, 1.0)] for counter in counter_groups]\n",
    "    counter_group_1_0 = [counter[(1, 0.0)] for counter in counter_groups]\n",
    "    counter_group_1_1 = [counter[(1, 1.0)] for counter in counter_groups]\n",
    "\n",
    "    # plot a barplot with counter_group_0_0, counter_group_0_1, counter_group_1_0, counter_group_1_1\n",
    "    # for each client in the same plot\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    plt.bar(range(len(counter_group_0_0)), counter_group_0_0)\n",
    "    plt.bar(range(len(counter_group_0_1)), counter_group_0_1, bottom=counter_group_0_0)\n",
    "    plt.bar(\n",
    "        range(len(counter_group_1_0)),\n",
    "        counter_group_1_0,\n",
    "        bottom=[sum(x) for x in zip(counter_group_0_0, counter_group_0_1)],\n",
    "    )\n",
    "    plt.bar(\n",
    "        range(len(counter_group_1_1)),\n",
    "        counter_group_1_1,\n",
    "        bottom=[\n",
    "            sum(x) for x in zip(counter_group_0_0, counter_group_0_1, counter_group_1_0)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Client\")\n",
    "    plt.ylabel(\"Amount of samples\")\n",
    "    plt.title(\"Samples for each group (target/sensitive Value) per client\")\n",
    "    plt.legend([\"0,0\", \"0,1\", \"1,0\", \"1,1\"])\n",
    "    # font size 20\n",
    "    plt.rcParams.update({\"font.size\": 20})\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # group_to_reduce=(0,1), group_to_increment=(1,1),\n",
    "    # 0, 0 -> 1, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "dill_file = open(\"income_data.pkd\", \"rb\")\n",
    "data = dill.load(dill_file)\n",
    "disparities = {}\n",
    "for state in data.keys():\n",
    "    labels = torch.tensor(data[state][\"labels\"].astype(int))\n",
    "    group = torch.tensor(\n",
    "        [1 if item == 1 else 0 for item in list(data[state][\"groups\"])]\n",
    "    )\n",
    "    max_disparity = np.max(\n",
    "        [\n",
    "            RegularizationLoss().compute_violation_with_argmax(\n",
    "                predictions_argmax=labels,\n",
    "                sensitive_attribute_list=group,\n",
    "                current_target=target,\n",
    "                current_sensitive_feature=sv,\n",
    "            )\n",
    "            for target in range(0, 1)\n",
    "            for sv in range(0, 1)\n",
    "        ]\n",
    "    )\n",
    "    disparities[state] = max_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(disparities.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_disparity(disparities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(disparities.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [\n",
    "    int(item) for item in [\"23\", \"45\", \"13\", \"15\", \"8\", \"33\", \"7\", \"2\", \"35\", \"3\"]\n",
    "]\n",
    "train_set = [\n",
    "    int(item)\n",
    "    for item in [\n",
    "        \"19\",\n",
    "        \"32\",\n",
    "        \"39\",\n",
    "        \"27\",\n",
    "        \"0\",\n",
    "        \"47\",\n",
    "        \"24\",\n",
    "        \"11\",\n",
    "        \"4\",\n",
    "        \"46\",\n",
    "        \"20\",\n",
    "        \"48\",\n",
    "        \"12\",\n",
    "        \"31\",\n",
    "        \"14\",\n",
    "        \"49\",\n",
    "        \"21\",\n",
    "        \"16\",\n",
    "        \"22\",\n",
    "        \"9\",\n",
    "        \"29\",\n",
    "        \"38\",\n",
    "        \"40\",\n",
    "        \"36\",\n",
    "        \"25\",\n",
    "        \"37\",\n",
    "        \"42\",\n",
    "        \"34\",\n",
    "        \"5\",\n",
    "        \"17\",\n",
    "        \"50\",\n",
    "    ]\n",
    "]\n",
    "valiation_set = [\n",
    "    int(item) for item in [\"30\", \"28\", \"10\", \"44\", \"18\", \"43\", \"26\", \"6\", \"41\", \"1\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = None\n",
    "all_labels = None\n",
    "all_groups = None\n",
    "\n",
    "for state in data.keys():\n",
    "    # extend the all_data, all_labels, all_groups pandas dataframe with the data from the current state\n",
    "    if all_data is None:\n",
    "        all_data = data[state][\"features_pd\"]\n",
    "        all_labels = data[state][\"labels_pd\"]\n",
    "        all_groups = data[state][\"groups_pd\"]\n",
    "    else:\n",
    "        all_data = pd.concat((all_data, data[state][\"features_pd\"]), axis=0)\n",
    "        all_labels = pd.concat((all_labels, data[state][\"labels_pd\"]), axis=0)\n",
    "        all_groups = pd.concat((all_groups, data[state][\"groups_pd\"]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "dill_file = open(\"employment_data.pkd\", \"rb\")\n",
    "data = dill.load(dill_file)\n",
    "disparities = {}\n",
    "for state in data.keys():\n",
    "    labels = torch.tensor(data[state][\"labels\"].astype(int))\n",
    "    group = torch.tensor(\n",
    "        [1 if item == 1 else 0 for item in list(data[state][\"groups\"])]\n",
    "    )\n",
    "    max_disparity = np.max(\n",
    "        [\n",
    "            RegularizationLoss().compute_violation_with_argmax(\n",
    "                predictions_argmax=labels,\n",
    "                sensitive_attribute_list=group,\n",
    "                current_target=target,\n",
    "                current_sensitive_feature=sv,\n",
    "            )\n",
    "            for target in range(0, 1)\n",
    "            for sv in range(0, 1)\n",
    "        ]\n",
    "    )\n",
    "    disparities[state] = max_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_disparity(disparities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_plot(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
