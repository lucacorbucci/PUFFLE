{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import dill\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"axes.xmargin\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sweeps(project):\n",
    "    sweeps = []\n",
    "    for sweep in project:\n",
    "        sweeps.append(sweep.id)\n",
    "    return sweeps[::-1]\n",
    "\n",
    "\n",
    "def get_run_links(sweeps, project_name):\n",
    "    runs = []\n",
    "    for sweep_link in sweeps:\n",
    "        sweep = wandb.Api().sweep(f\"lucacorbucci/{project_name}/{sweep_link}\")\n",
    "        run_list_sweep = []\n",
    "        for run in sweep.runs:\n",
    "            run_list_sweep.append(run.id)\n",
    "        runs.append(run_list_sweep[::-1])\n",
    "    return runs\n",
    "\n",
    "\n",
    "def get_run_data(run_links_per_sweep, project_name):\n",
    "    run_data = []\n",
    "    for sweep in run_links_per_sweep:\n",
    "        tmp_run_data = []\n",
    "        for run_link in sweep:\n",
    "            run = wandb.Api().run(f\"lucacorbucci/{project_name}/{run_link}\")\n",
    "            tmp_run_data.append(pd.DataFrame(run.scan_history()))\n",
    "        run_data.append(tmp_run_data)\n",
    "    return run_data\n",
    "\n",
    "\n",
    "def remove_nan(column_names, dataframe):\n",
    "    column_names = [\n",
    "        column_name for column_name in column_names if column_name in dataframe.columns\n",
    "    ]\n",
    "\n",
    "    current_df = dataframe[column_names]\n",
    "    # consider each column in training_data_disparity independently and\n",
    "    # remove the rows where we have NaN\n",
    "    new_columns = []\n",
    "\n",
    "    for column in current_df.columns:\n",
    "        new_values = list(current_df[column].dropna())\n",
    "        new_columns.append(new_values)\n",
    "\n",
    "    # if the lists have different lengths, we need to modify them so that\n",
    "    # we have the same length:\n",
    "    min_size = min([len(item) for item in new_columns])\n",
    "    new_columns = [item[:min_size] for item in new_columns]\n",
    "\n",
    "    # create the new dataframe with baseline_test_nodes_columns_disparity_dataset as columns\n",
    "    # names and new_columns as values\n",
    "    new_df = pd.DataFrame(dict(zip(column_names, new_columns)))\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def create_avg_dataset(new_list):\n",
    "    # compute the mean and the std of the data in new_list\n",
    "    # and create a new dataset with these values\n",
    "    mean = np.mean(new_list, axis=0)\n",
    "    std = np.std(new_list, axis=0)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    new_mean = []\n",
    "    current_max = 0\n",
    "    for value in mean:\n",
    "        if value > current_max:\n",
    "            current_max = value\n",
    "            new_mean.append(current_max)\n",
    "        else:\n",
    "            new_mean.append(None)\n",
    "    df[\"mean\"] = mean\n",
    "    df[\"dots\"] = new_mean\n",
    "    df[\"std\"] = std\n",
    "    df[\"index\"] = list(range(0, len(mean)))\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_pareto_frontier(data_lists):\n",
    "    custom_metrics = []\n",
    "    current_max = 0\n",
    "    for value in data_lists:\n",
    "        if value >= current_max:\n",
    "            current_max = value\n",
    "        custom_metrics.append(current_max)\n",
    "\n",
    "    return custom_metrics\n",
    "\n",
    "\n",
    "def create_avg_dataset(new_list):\n",
    "    # compute the mean and the std of the data in new_list\n",
    "    # and create a new dataset with these values\n",
    "    mean = np.mean(new_list, axis=0)\n",
    "    std = np.std(new_list, axis=0)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    new_mean = []\n",
    "    current_max = 0\n",
    "    for value in mean:\n",
    "        if value > current_max:\n",
    "            current_max = value\n",
    "            new_mean.append(current_max)\n",
    "        else:\n",
    "            new_mean.append(None)\n",
    "    df[\"mean\"] = mean\n",
    "    df[\"dots\"] = new_mean\n",
    "    df[\"std\"] = std\n",
    "    df[\"index\"] = list(range(0, len(mean)))\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_last_custom_metrics(sweep):\n",
    "    custom_metrics = []\n",
    "    for sweep_dfs in sweep:\n",
    "        tmp_custom_metrics = []\n",
    "        for df in sweep_dfs:\n",
    "            custom_metric = remove_nan([\"Custom_metric\"], df)\n",
    "            tmp_custom_metrics.append(custom_metric.values.tolist()[-1][0])\n",
    "        custom_metrics.append(tmp_custom_metrics)\n",
    "    return custom_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dutch_Baseline_05_project_name = \"Dutch_Baseline_05\"\n",
    "Dutch_Baseline_05_project = wandb.Api().project(Dutch_Baseline_05_project_name).sweeps()\n",
    "Dutch_Baseline_05_sweeps = get_sweeps(Dutch_Baseline_05_project)\n",
    "Dutch_Baseline_05_run_links = get_run_links(\n",
    "    Dutch_Baseline_05_sweeps, Dutch_Baseline_05_project_name\n",
    ")\n",
    "data = get_run_data(Dutch_Baseline_05_run_links, Dutch_Baseline_05_project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_metrics = extract_last_custom_metrics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_list = prepare_pareto_frontier(custom_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pareto = create_avg_dataset(pareto_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
