program: ../../main.py
method: bayes
metric:
  name: Custom_metric
  goal: maximize
early_terminate:
  type: hyperband
  min_iter: 5
parameters:
  epochs:
    min: 1
    max: 5
  batch_size:
    min: 128
    max: 512
  lr:
    min: 0.0001
    max: 0.1
  optimizer:
    values: ["adam", "sgd", "adamw"]
  node_shuffle_seed:
    min: 1
    max: 1000000000
  starting_lambda_value:
    min: 0.40
    max: 0.90
  clipping:
    min: 2
    max: 5

command:
  - ${env}
  - poetry 
  - run 
  - python
  - ${program}
  - ${args}
  - --dataset
  - celeba
  - --num_rounds
  - 25
  - --num_client_cpus
  - 1
  - --num_client_gpus
  - 0.5
  - --pool_size
  - 150
  - --sampled_clients 
  - 0.20
  - --sampled_clients_test 
  - 1.0
  - --sampled_clients_validation 
  - 1.0
  - --train_csv
  - original_merged
  - --debug
  - True 
  - --base_path
  - ../../../data
  - --DPL 
  - True 
  - --private 
  - True 
  - --delta 
  - 1e-4 
  - --partition_type 
  - balanced_and_unbalanced 
  - --alpha 
  - 5 
  - --seed 
  - 41 
  - --wandb 
  - True 
  - --sweep
  - True
  - --training_nodes 
  - 0.40
  - --validation_nodes 
  - 0.27
  - --test_nodes 
  - 0.335
  - --starting_lambda_mode 
  - fixed
  - --target 
  - 0.05
  - --percentage_unbalanced_nodes
  - 0.5
  - --unbalanced_ratio
  - 0.5
  - --dataset_path 
  - ../../../data/celeba
  - --epsilon
  - 10