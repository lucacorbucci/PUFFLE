{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca.corbucci/fl_puf/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-14 10:08:47,465\tINFO util.py:159 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from DPL.Utils.model_utils import ModelUtils\n",
    "import torch\n",
    "from fl_puf.Utils.utils import Utils\n",
    "from Utils.train_parameters import TrainParameters\n",
    "from opacus import PrivacyEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ModelUtils.get_model(\"celeba\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_128 = Utils.get_dataloader(\n",
    "    \"../data/celeba/celeba-10-batches-py/federated\",\n",
    "    \"0\",\n",
    "    batch_size=128,\n",
    "    workers=0,\n",
    "    dataset=\"celeba\",\n",
    "    partition=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca.corbucci/fl_puf/.venv/lib/python3.8/site-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.932373046875"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 100\n",
    "epsilon = 10\n",
    "delta = 1e-5\n",
    "clipping_value = 5.0\n",
    "(\n",
    "    private_model,\n",
    "    private_optimizer,\n",
    "    private_train_loader,\n",
    ") = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader_128,\n",
    "    epochs=epochs,\n",
    "    target_epsilon=epsilon,\n",
    "    target_delta=delta,\n",
    "    max_grad_norm=clipping_value,\n",
    ")\n",
    "\n",
    "# Ora mi sono creato il modello privato, ho tutti i vari parametri\n",
    "# e posso calcolare quale rumore è necessario aggiungere \n",
    "# ogni volta che tocco i dati durante il training basandomi sulla\n",
    "# epsilon che voglio avere alla fine e sugli altri parametri.\n",
    "private_optimizer.noise_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelUtils.get_model(\"celeba\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_512 = Utils.get_dataloader(\n",
    "    \"../data/celeba/celeba-10-batches-py/federated\",\n",
    "    \"0\",\n",
    "    batch_size=512,\n",
    "    workers=0,\n",
    "    dataset=\"celeba\",\n",
    "    partition=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1787109375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 100\n",
    "epsilon = 10\n",
    "delta = 1e-5\n",
    "clipping_value = 5.0\n",
    "(\n",
    "    private_model,\n",
    "    private_optimizer,\n",
    "    private_train_loader,\n",
    ") = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader_512,\n",
    "    epochs=epochs,\n",
    "    target_epsilon=epsilon,\n",
    "    target_delta=delta,\n",
    "    max_grad_norm=clipping_value,\n",
    ")\n",
    "\n",
    "# Qui rispetto all'esperimento precedente ho cambiato il batch size\n",
    "# Quindi aggiungo più rumore\n",
    "private_optimizer.noise_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1787109375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader_512 = Utils.get_dataloader(\n",
    "    \"../data/celeba/celeba-10-batches-py/federated\",\n",
    "    \"0\",\n",
    "    batch_size=512,\n",
    "    workers=0,\n",
    "    dataset=\"celeba\",\n",
    "    partition=\"train\",\n",
    ")\n",
    "model = ModelUtils.get_model(\"celeba\", device=device)\n",
    "\n",
    "privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 100\n",
    "epsilon = 10\n",
    "delta = 1e-5\n",
    "clipping_value = 10.0\n",
    "(\n",
    "    private_model,\n",
    "    private_optimizer,\n",
    "    private_train_loader,\n",
    ") = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader_512,\n",
    "    epochs=epochs,\n",
    "    target_epsilon=epsilon,\n",
    "    target_delta=delta,\n",
    "    max_grad_norm=clipping_value,\n",
    ")\n",
    "\n",
    "# Anche se ho cambiato il clipping il noise non cambia!!\n",
    "private_optimizer.noise_multiplier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
