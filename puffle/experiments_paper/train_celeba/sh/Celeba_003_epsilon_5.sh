# fixed
# poetry run python ../../../main.py --batch_size=415 --clipping=12.641281638195204 --epochs=4 --lr=0.09656621475137124 --node_shuffle_seed=599826842 --optimizer=adam --starting_lambda_value=0.7282549317811405 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 4.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_fixed
# poetry run python ../../../main.py --batch_size=415 --clipping=12.641281638195204 --epochs=4 --lr=0.09656621475137124 --node_shuffle_seed=599826843 --optimizer=adam --starting_lambda_value=0.7282549317811405 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 4.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_fixed
# poetry run python ../../../main.py --batch_size=415 --clipping=12.641281638195204 --epochs=4 --lr=0.09656621475137124 --node_shuffle_seed=599826844 --optimizer=adam --starting_lambda_value=0.7282549317811405 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 4.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_fixed
# poetry run python ../../../main.py --batch_size=415 --clipping=12.641281638195204 --epochs=4 --lr=0.09656621475137124 --node_shuffle_seed=599826845 --optimizer=adam --starting_lambda_value=0.7282549317811405 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 4.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_fixed
# poetry run python ../../../main.py --batch_size=415 --clipping=12.641281638195204 --epochs=4 --lr=0.09656621475137124 --node_shuffle_seed=599826846 --optimizer=adam --starting_lambda_value=0.7282549317811405 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 4.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_fixed


# tunable
poetry run python ../../../main.py --alpha_target_lambda=3.6723461921970353 --batch_size=330 --clipping=4.970186356688892 --epochs=3 --lr=0.06783380135314751 --momentum=0.275583062032348 --node_shuffle_seed=295425886 --optimizer=adam --weight_decay_lambda=0.2431433410724864 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 4 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_tunable_debug
poetry run python ../../../main.py --alpha_target_lambda=3.6723461921970353 --batch_size=330 --clipping=4.970186356688892 --epochs=3 --lr=0.06783380135314752 --momentum=0.275583062032348 --node_shuffle_seed=295425887 --optimizer=adam --weight_decay_lambda=0.2431433410724864 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 4 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_tunable_debug
poetry run python ../../../main.py --alpha_target_lambda=3.6723461921970353 --batch_size=330 --clipping=4.970186356688892 --epochs=3 --lr=0.06783380135314753 --momentum=0.275583062032348 --node_shuffle_seed=295425888 --optimizer=adam --weight_decay_lambda=0.2431433410724864 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 4 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_tunable_debug
poetry run python ../../../main.py --alpha_target_lambda=3.6723461921970353 --batch_size=330 --clipping=4.970186356688892 --epochs=3 --lr=0.06783380135314754 --momentum=0.275583062032348 --node_shuffle_seed=295425889 --optimizer=adam --weight_decay_lambda=0.2431433410724864 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 4 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_tunable_debug
poetry run python ../../../main.py --alpha_target_lambda=3.6723461921970353 --batch_size=330 --clipping=4.970186356688892 --epochs=3 --lr=0.06783380135314755 --momentum=0.275583062032348 --node_shuffle_seed=295425880 --optimizer=adam --weight_decay_lambda=0.2431433410724864 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 4 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_5_tunable_debug
