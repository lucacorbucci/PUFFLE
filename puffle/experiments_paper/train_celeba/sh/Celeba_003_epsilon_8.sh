# # fixed
# poetry run python ../../../main.py --batch_size=285 --clipping=12.092258729317408 --epochs=4 --lr=0.08439192707250584 --node_shuffle_seed=562280381 --optimizer=sgd --starting_lambda_value=0.7425600543313425 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_fixed
# poetry run python ../../../main.py --batch_size=285 --clipping=12.092258729317408 --epochs=4 --lr=0.08439192707250584 --node_shuffle_seed=562280382 --optimizer=sgd --starting_lambda_value=0.7425600543313425 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_fixed
# poetry run python ../../../main.py --batch_size=285 --clipping=12.092258729317408 --epochs=4 --lr=0.08439192707250584 --node_shuffle_seed=562280383 --optimizer=sgd --starting_lambda_value=0.7425600543313425 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_fixed
# poetry run python ../../../main.py --batch_size=285 --clipping=12.092258729317408 --epochs=4 --lr=0.08439192707250584 --node_shuffle_seed=562280384 --optimizer=sgd --starting_lambda_value=0.7425600543313425 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_fixed
# poetry run python ../../../main.py --batch_size=285 --clipping=12.092258729317408 --epochs=4 --lr=0.08439192707250584 --node_shuffle_seed=562280385 --optimizer=sgd --starting_lambda_value=0.7425600543313425 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_fixed

# # tunable 
# poetry run python ../../../main.py --alpha_target_lambda=2.4225896438454817 --batch_size=111 --clipping=11.744404109451777 --epochs=1 --lr=0.0837333480850254 --momentum=0.4568588320323476 --node_shuffle_seed=375421338 --optimizer=sgd --weight_decay_lambda=0.21071182700912228 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_tunable
# poetry run python ../../../main.py --alpha_target_lambda=2.4225896438454817 --batch_size=111 --clipping=11.744404109451777 --epochs=1 --lr=0.0837333480850254 --momentum=0.4568588320323476 --node_shuffle_seed=375421339 --optimizer=sgd --weight_decay_lambda=0.21071182700912228 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_tunable
# poetry run python ../../../main.py --alpha_target_lambda=2.4225896438454817 --batch_size=111 --clipping=11.744404109451777 --epochs=1 --lr=0.0837333480850254 --momentum=0.4568588320323476 --node_shuffle_seed=375421330 --optimizer=sgd --weight_decay_lambda=0.21071182700912228 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_tunable
# poetry run python ../../../main.py --alpha_target_lambda=2.4225896438454817 --batch_size=111 --clipping=11.744404109451777 --epochs=1 --lr=0.0837333480850254 --momentum=0.4568588320323476 --node_shuffle_seed=375421331 --optimizer=sgd --weight_decay_lambda=0.21071182700912228 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_tunable
# poetry run python ../../../main.py --alpha_target_lambda=2.4225896438454817 --batch_size=111 --clipping=11.744404109451777 --epochs=1 --lr=0.0837333480850254 --momentum=0.4568588320323476 --node_shuffle_seed=375421332 --optimizer=sgd --weight_decay_lambda=0.21071182700912228 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.0375 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_003_epsilon_8_tunable
