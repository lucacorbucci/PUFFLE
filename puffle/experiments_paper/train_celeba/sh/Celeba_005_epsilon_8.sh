# fixed 
poetry run python ../../../main.py --batch_size=205 --clipping=13.51883468944616 --epochs=5 --lr=0.0830613677950049 --node_shuffle_seed=992511156 --optimizer=adam --starting_lambda_value=0.7667799526635715 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_fixed_debug
poetry run python ../../../main.py --batch_size=205 --clipping=13.51883468944617 --epochs=5 --lr=0.0830613677950049 --node_shuffle_seed=992511157 --optimizer=adam --starting_lambda_value=0.7667799526635715 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_fixed_debug
poetry run python ../../../main.py --batch_size=205 --clipping=13.51883468944618 --epochs=5 --lr=0.0830613677950049 --node_shuffle_seed=992511158 --optimizer=adam --starting_lambda_value=0.7667799526635715 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_fixed_debug
poetry run python ../../../main.py --batch_size=205 --clipping=13.51883468944619 --epochs=5 --lr=0.0830613677950049 --node_shuffle_seed=992511159 --optimizer=adam --starting_lambda_value=0.7667799526635715 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_fixed_debug
poetry run python ../../../main.py --batch_size=205 --clipping=13.51883468944610 --epochs=5 --lr=0.0830613677950049 --node_shuffle_seed=992511150 --optimizer=adam --starting_lambda_value=0.7667799526635715 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode fixed --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon 7.5 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_fixed_debug

# tunable 
poetry run python ../../../main.py --alpha_target_lambda=1.162953148122455 --batch_size=354 --clipping=6.263422221258371 --epochs=5 --lr=0.05681576160143053 --momentum=0.8534432584201085 --node_shuffle_seed=826302782 --optimizer=sgd --weight_decay_lambda=0.2971071394634666 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_tunable_debug
poetry run python ../../../main.py --alpha_target_lambda=1.162953148122455 --batch_size=354 --clipping=6.263422221258372 --epochs=5 --lr=0.05681576160143053 --momentum=0.8534432584201085 --node_shuffle_seed=826302783 --optimizer=sgd --weight_decay_lambda=0.2971071394634666 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_tunable_debug
poetry run python ../../../main.py --alpha_target_lambda=1.162953148122455 --batch_size=354 --clipping=6.263422221258373 --epochs=5 --lr=0.05681576160143053 --momentum=0.8534432584201085 --node_shuffle_seed=826302784 --optimizer=sgd --weight_decay_lambda=0.2971071394634666 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_tunable_debug
poetry run python ../../../main.py --alpha_target_lambda=1.162953148122455 --batch_size=354 --clipping=6.263422221258374 --epochs=5 --lr=0.05681576160143053 --momentum=0.8534432584201085 --node_shuffle_seed=826302785 --optimizer=sgd --weight_decay_lambda=0.2971071394634666 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_tunable_debug
poetry run python ../../../main.py --alpha_target_lambda=1.162953148122455 --batch_size=354 --clipping=6.263422221258375 --epochs=5 --lr=0.05681576160143053 --momentum=0.8534432584201085 --node_shuffle_seed=826302786 --optimizer=sgd --weight_decay_lambda=0.2971071394634666 --dataset celeba --num_rounds 39 --num_client_cpus 1 --num_client_gpus 0.05 --pool_size 150 --sampled_clients 0.30 --sampled_clients_test 1.0 --train_csv original_merged --debug False --base_path ../../../../data --dataset_path ../../../../data/celeba --private True --DPL True --seed 41 --wandb True --training_nodes 0.67 --test_nodes 0.335 --starting_lambda_mode disparity --update_lambda True --target 0.05 --partition_type representative --group_to_reduce 1 1 --group_to_increment 0 1 --number_of_samples_per_node 1350 --ratio_unfair_nodes 0.5 --ratio_unfairness 0.9 0.9 --epsilon_lambda 0.5 --epsilon 7 --epsilon_statistics 0.5 --one_group_nodes True --project_name Celeba_Paper --run_name Celeba_005_epsilon_8_tunable_debug